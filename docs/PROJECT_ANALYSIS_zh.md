# DataArc SynData Toolkit: 深度研究报告

## 🏗️ 架构概览

**DataArc SynData Toolkit** 是一个旨在实现高质量合成数据生成 (SDG) 及其后续模型微调的模块化框架。其架构采用了解耦设计，允许在数据生命周期的每个阶段进行灵活的定制。

---

## 🧩 核心组件

### 1. 流水线编排器 (`sdgsystem/pipeline.py`)
系统的核心。它负责管理端到端的流程：
- **执行**：触发生成任务。
- **评估**：执行二元（已解决/未解决）和基于评分的质量检查。
- **优化**：使用重写器调整过难或过易的样本。
- **分类**：将结果拆分为三个不同的数据集，用于针对性的训练。

### 2. 任务执行器 (`sdgsystem/tasks/`)
- **本地 (`local.py`)**：实现了一个 RAG（检索增强生成）流水线。它解析本地 PDF/文档，对其进行切片，提取领域关键词，并使用 BM25 检索为生成提供背景信息。
- **Web (`web.py`)**：自动化地从 Huggingface 发现并过滤高质量数据集。
- **蒸馏 (`distill.py`)**：协助从教师模型生成训练数据。

### 3. 模型管理 (`sdgsystem/models/`)
- **统一客户端**：包装了各种后端（本地使用 vLLM，API 使用 OpenAI/DeepSeek/Ollama）。
- **延迟加载**：仅在需要时才将本地模型加载到显存 (VRAM) 中。
- **后处理**：包含诸如 **多数投票**（精确匹配、语义聚类或基于 LLM）的机制，以确保高质量的答案。

### 4. 并行执行与缓冲 (`sdgsystem/parallel.py`, `sdgsystem/buffer.py`)
- **加速**：使用 `ThreadPoolExecutor` 并行化 Prompt 生成和评估。
- **弹性**：任务缓冲区将进度保存到磁盘，允许流水线在中断后从上一个成功的阶段恢复，从而节省时间并节省 API token。

### 5. 后训练 (`verl/`)
该工具包集成了 `verl` 框架，使用户能够从数据生成无缝过渡到模型训练：
- **SFT**：监督微调 (Supervised Fine-Tuning)。
- **GRPO**：群体相对策略优化 (Group Relative Policy Optimization)，专为 RLHF 和推理任务而设计。

---

## 🔄 执行工作流

1.  **配置**：用户在 YAML 文件中定义任务类型和模型提供商。
2.  **生成**：系统提取领域关键词并生成初始样本（对于本地任务支持 RAG）。
3.  **初始质量门控**：学生模型尝试“解决”生成的样本。
4.  **重写循环**：未解决或过于简单的样本由教师模型重写，以达到训练难度的“甜蜜点”（即 **可学习** 集）。
5.  **最终质量门控**：对样本进行重新评估和分类。
6.  **导出/训练**：导出分类后的数据，并调用 `verl` 进行 SFT 或 GRPO 训练。

## 🛠️ 定制化潜力

项目设计考虑了扩展性：
- **自定义任务**：继承自 `BaseTaskConfig` 和 `BaseTaskExecutor`。
- **自定义重写**：继承自 `BaseRewriteConfig` 和 `BaseRewriter`。
- **新模型**：通过配置通过 OpenAI 兼容的提供商轻松添加任何模型。
